
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Natural Language Processing &#8212; Coding for Economists</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-9FZQCPFXZJ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-9FZQCPFXZJ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-9FZQCPFXZJ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'text-nlp';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://aeturrell.github.io/coding-for-economists/text-nlp.html" />
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction to Machine Learning and AI" href="ml-intro.html" />
    <link rel="prev" title="Regular Expressions, aka regex" href="text-regex.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/smith_lovelace.png" class="logo__image only-light" alt="Coding for Economists - Home"/>
    <script>document.write(`<img src="_static/smith_lovelace.png" class="logo__image only-dark" alt="Coding for Economists - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="code-preliminaries.html">Preliminaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="code-basics.html">Coding Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow-basics.html">Workflow Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="code-where.html">Writing Code</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essential Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data-analysis-quickstart.html">Data Analysis Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-intro.html">Working with Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-transformation.html">Data Transformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-read-and-write.html">Reading and Writing Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-numbers.html">Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-categorical.html">Categorical Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-spreadsheets.html">Spreadsheets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essential Coding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="code-best-practice.html">Code in Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="code-advanced.html">Coding</a></li>
<li class="toctree-l1"><a class="reference internal" href="code-advcd-best-practice.html">Shortcuts to Better Coding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essential Data Visualisation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vis-intro.html">Intro to Data Visualisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-letsplot.html">Easy Data Visualisation for Tidy Data with <strong>Lets-Plot</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-matplotlib.html">Powerful Data Visualisation with <strong>Matplotlib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-common-plots-one.html">Common Plots I</a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-common-plots-two.html">Common Plots II</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Essential Workflow</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="auto-research-outputs.html">Automating Research Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrkflow-markdown.html">Markdown</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrkflow-command-line.html">The Command Line</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrkflow-version-control.html">Version Control</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Econometrics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="econmt-probability-random.html">Probability and Random Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-statistics.html">Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-regression.html">Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-generalised-models.html">Generalised regression models</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-diagnostics.html">Regression diagnostics and visualisations</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-causal-inference.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-bayesian.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="econmt-bayes-bambi.html">Bayesian Inference Made Easier</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data-boolean.html">Boolean Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-joining-data.html">Joins</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-missing-values.html">Missing Values</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-exploratory-analysis.html">Exploratory Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-extraction.html">Getting Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-advanced.html"><strong>pandas</strong> alternatives, validation, and orchestration</a></li>
<li class="toctree-l1"><a class="reference internal" href="data-sharing.html">Sharing Data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Coding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="code-further-advanced.html">Advanced Coding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Visualisation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vis-narrative.html">Narrative Data Visualisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-tables.html">Tables</a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-dashboards.html">Dashboards</a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-animation.html">Animation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Workflow</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="wrkflow-quarto.html">Combining Code and Text in Quarto Markdown</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrkflow-environments.html">Virtual Code Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrkflow-rap.html">Reproducible Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Time</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="time-intro.html">Introduction to Time</a></li>
<li class="toctree-l1"><a class="reference internal" href="time-series.html">Time Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="time-fcasts-env.html">Forecasting Exercises</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Text Analysis</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="text-intro.html">Introduction to Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="text-regex.html">Regular Expressions, aka regex</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Natural Language Processing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml-intro.html">Introduction to Machine Learning and AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-sup.html">Supervised Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-data.html">Data for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml-unsup.html">Unsupervised Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Geospatial</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="geo-intro.html">Intro to Geo-Spatial Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="geo-vis.html">Geo-Spatial Visualisation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Mathematics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="maths-abstract.html">Abstract Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="maths-numerical.html">Numerical Mathematics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Craft</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="craft-intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-search.html">Putting the Search in Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-generating-ideas.html">Generating and Accepting Research Ideas</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-writing-papers.html">Writing Papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-research-blogs.html">Research Blog Posts</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-referee.html">Writing Referee Reports</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-technical-reports.html">Writing Technical Reports</a></li>
<li class="toctree-l1"><a class="reference internal" href="craft-extended-abstracts.html">Extended Abstracts</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Further Data Visualisation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="vis-plotnine.html">Data Visualisation using the Grammar of Graphics with <strong>Plotnine</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="vis-seaborn.html">Data Visualisation with <strong>Seaborn</strong></a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Coming from ...</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="coming-from-stata.html">Coming from Stata</a></li>
<li class="toctree-l1"><a class="reference internal" href="coming-from-matlab.html">Coming from Matlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="coming-from-r.html">Coming from R</a></li>
<li class="toctree-l1"><a class="reference internal" href="coming-from-excel.html">Coming from Excel</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">End Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="zreferences.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/aeturrell/coding-for-economists/blob/main/text-nlp.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/aeturrell/coding-for-economists" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/aeturrell/coding-for-economists/issues/new?title=Issue%20on%20page%20%2Ftext-nlp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/text-nlp.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Natural Language Processing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation">Tokenisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-with-regular-expressions">Tokenisation with regular expressions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-using-nlp-tools">Tokenisation using NLP tools</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#removing-stop-words">Removing Stop Words</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#counting-text">Counting Text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentence-tokenisation-and-reading-in-text-as-sentences">Sentence Tokenisation (and reading in text as sentences)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-idf">TF-IDF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-inner-product-and-cosine-similarity">Vector Inner Product and Cosine Similarity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transform-versus-fit-transform">Transform versus Fit Transform</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-a-special-vocabulary">Using a Special Vocabulary</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-out-frequent-and-infrequent-words">Filtering Out Frequent and Infrequent Words</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#context-of-terms">Context of Terms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stemming-and-lemmatisation">Stemming and Lemmatisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-of-speech-tagging">Part of Speech Tagging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#readability-statistics">Readability Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#see-also">See Also</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#review">Review</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="natural-language-processing">
<h1>Natural Language Processing<a class="headerlink" href="#natural-language-processing" title="Link to this heading">#</a></h1>
<p>This chapter covers text analysis, also known as natural language processing. We’ll cover tokenisation of text, removing stop words, counting words, performing other statistics on words, and analysing the parts of speech. The focus here is on English, but many of the methods-and even the libraries-are relevant to other languages too.</p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>When doing NLP, it’s worth thinking carefully about the unit of analysis: is it a corpus, a text, a line, a paragraph, a sentence, a word, or even a character? It could also be two of these simultaneously, and working with document x token matrices is one very common way of doing NLP. Although we’ll be mixing between a few of these in this chapter, thinking about what the block of text data you’re working with will really help you keep track of what operations are being deployed and how they might interact.</p>
<p>In case it’s also useful to know, three of the most loved NLP packages are <a class="reference external" href="https://www.nltk.org/"><strong>nltk</strong></a>, <a class="reference external" href="https://spacy.io/"><strong>spaCy</strong></a>, and <a class="reference external" href="https://radimrehurek.com/gensim/"><strong>gensim</strong></a>. As you progress through the chapter, you should also bear in mind that some of the methods we’ll see are computationally expensive and you might want to fall back on simpler approaches, such as those seen in the previous chapter, if you have large volumes of text.</p>
<p>In this chapter, we’ll use a single example and using NLP on it in a few different ways. First, though, we need to read in the text data we’ll be using, part of Adam Smith’s <em>The Wealth of Nations</em> and do some light cleaning of it.</p>
<p>Initially, we’ll read in our text so that each new line appears on a different row of a <strong>pandas</strong> dataframe. We will end up working with it both as a vector of lines and, later, as a vector of lists of words. We’ll also import the packages we’ll need; remember, you may need to install these first and the Chapter on <a class="reference internal" href="code-preliminaries.html#code-preliminaries"><span class="std std-ref">Preliminaries</span></a> provides a brief guide on how to do this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">string</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/aeturrell/coding-for-economists/raw/main/data/smith_won.txt&quot;</span><span class="p">,</span>
    <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>An Inquiry into the Nature and Causes of the...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>POWERS OF LABOUR, AND OF THE ORDER ACCORDING T...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>DISTRIBUTED AMONG THE DIFFERENT RANKS OF THE P...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>DIVISION OF LABOUR.     CHAPTER III. THAT THE ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>THE EXTENT OF THE MARKET.     CHAPTER IV. OF T...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We need to do a bit of light text cleaning before we get on to the more in-depth natural language processing. We’ll make use of vectorised string operations as seen in the <a class="reference internal" href="text-intro.html#text-intro"><span class="std std-ref">Introduction to Text</span></a> chapter. First, we want to put everything in lower case:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>an inquiry into the nature and causes of the...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>powers of labour, and of the order according t...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>distributed among the different ranks of the p...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>division of labour.     chapter iii. that the ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>the extent of the market.     chapter iv. of t...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Next, we’ll remove the punctuation from the text. You may not always wish to do this but it’s a good default.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">translator</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="o">.</span><span class="n">maketrans</span><span class="p">({</span><span class="n">x</span><span class="p">:</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">})</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">translator</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>an inquiry into the nature and causes of the...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>powers of labour and of the order according to...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>distributed among the different ranks of the p...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>division of labour     chapter iii that the di...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>the extent of the market     chapter iv of the...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Okay, we now have rows and rows of lower case words without punctuation.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Remove all vowels from the vector of text using <code class="docutils literal notranslate"><span class="pre">str.translate()</span></code>.</p>
</div>
<p>While we’re doing some text cleaning, let’s also remove the excess whitespace found in, for example, the first entry. Leaning on the cleaning methods from the previous chapter, we’ll use regular expressions to do this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;\s+?\W+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This searches for multiple whitespaces that preceede non-word characters and replaces them with a single whitespace.</p>
</section>
<section id="tokenisation">
<h2>Tokenisation<a class="headerlink" href="#tokenisation" title="Link to this heading">#</a></h2>
<p>We’re going to now see an example of tokenisation: the process of taking blocks of text and breaking them down into tokens, most commonly a word but potentially all one and two word pairs. Note that you might sometimes see all two word pairs referred to as 2-grams, with an n-gram being all phrases of n words. There are many ways to tokenise text; we’ll look at two of the most common: using regular expressions and using pre-configured NLP packages.</p>
<section id="tokenisation-with-regular-expressions">
<h3>Tokenisation with regular expressions<a class="headerlink" href="#tokenisation-with-regular-expressions" title="Link to this heading">#</a></h3>
<p>Because regular expressions excel at finding patterns in text, they can also be used to decide where to split text up into tokens. For a very simple example, let’s take the first line of our text example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="n">word_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;\w+&quot;</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">word_pattern</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">tokens</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;an&#39;,
 &#39;inquiry&#39;,
 &#39;into&#39;,
 &#39;the&#39;,
 &#39;nature&#39;,
 &#39;and&#39;,
 &#39;causes&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;wealth&#39;,
 &#39;of&#39;,
 &#39;nations&#39;,
 &#39;by&#39;,
 &#39;adam&#39;,
 &#39;smith&#39;,
 &#39;contents&#39;,
 &#39;introduction&#39;,
 &#39;and&#39;,
 &#39;plan&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;work&#39;,
 &#39;book&#39;,
 &#39;i&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;causes&#39;,
 &#39;of&#39;,
 &#39;improvement&#39;,
 &#39;in&#39;,
 &#39;the&#39;,
 &#39;productive&#39;]
</pre></div>
</div>
</div>
</div>
<p>This produced a split of a single line into one word tokens that are represented by a list of strings. We could have also asked for other variations, eg sentences, by asking to split at every “.”.</p>
</section>
<section id="tokenisation-using-nlp-tools">
<h3>Tokenisation using NLP tools<a class="headerlink" href="#tokenisation-using-nlp-tools" title="Link to this heading">#</a></h3>
<p>Many of the NLP packages available in Python come with built-in tokenisation tools. We’ll use nltk for tokenisation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">word_tokenize</span>

<span class="n">word_tokenize</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;an&#39;,
 &#39;inquiry&#39;,
 &#39;into&#39;,
 &#39;the&#39;,
 &#39;nature&#39;,
 &#39;and&#39;,
 &#39;causes&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;wealth&#39;,
 &#39;of&#39;,
 &#39;nations&#39;,
 &#39;by&#39;,
 &#39;adam&#39;,
 &#39;smith&#39;,
 &#39;contents&#39;,
 &#39;introduction&#39;,
 &#39;and&#39;,
 &#39;plan&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;work&#39;,
 &#39;book&#39;,
 &#39;i&#39;,
 &#39;of&#39;,
 &#39;the&#39;,
 &#39;causes&#39;,
 &#39;of&#39;,
 &#39;improvement&#39;,
 &#39;in&#39;,
 &#39;the&#39;,
 &#39;productive&#39;]
</pre></div>
</div>
</div>
</div>
<p>We have the same results as before when we used regex. Now let’s scale this tokenisation up to our whole corpus while retaining the lines of text, giving us a structure of the form (lines x tokens):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>an inquiry into the nature and causes of the ...</td>
      <td>[an, inquiry, into, the, nature, and, causes, ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>powers of labour and of the order according to...</td>
      <td>[powers, of, labour, and, of, the, order, acco...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>distributed among the different ranks of the p...</td>
      <td>[distributed, among, the, different, ranks, of...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>division of labour chapter iii that the divisi...</td>
      <td>[division, of, labour, chapter, iii, that, the...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>the extent of the market chapter iv of the ori...</td>
      <td>[the, extent, of, the, market, chapter, iv, of...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>nltk</strong> also has a <code class="docutils literal notranslate"><span class="pre">sent_tokenize()</span></code> function that tokenises sentences, although as it makes use of punctuation you must take care with what pre-cleaning of text you undertake.</p>
</section>
</section>
<section id="removing-stop-words">
<h2>Removing Stop Words<a class="headerlink" href="#removing-stop-words" title="Link to this heading">#</a></h2>
<p>Stop words are frequent but uninformative words such as ‘that’, ‘which’, ‘the’, ‘is’, ‘and’, and ‘but’. These words tend to be very common in the English language, but knowing that they appear frequently in a corpus doesn’t really tell us much. Therefore, it is quite common to strip these ‘stop’ words out of text before doing any count-based analysis (or to use methods that implicitly ignore them). Many NLP libraries come with built-in methods that remove stop words.</p>
<p>In this example of removing stop words, we’ll use the <a class="reference external" href="https://www.nltk.org/"><strong>nltk</strong></a> library. We’ll filter out any stopwords from the first entry in the tokens columns of our dataframe. Note that stop are often an add-on to a base library, and so are not always available from installing a package alone-one often needs to download the stop words relevant to whatever language you’re working with.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">nltk</span>

<span class="n">stopwords</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span>
    <span class="s2">&quot;english&quot;</span>
<span class="p">)</span>  <span class="c1"># Note that you may need to download these on your machine using nltk.download() within Python</span>
<span class="n">words_filtered</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;tokens&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
<span class="p">]</span>
<span class="n">words_filtered</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;inquiry&#39;,
 &#39;nature&#39;,
 &#39;causes&#39;,
 &#39;wealth&#39;,
 &#39;nations&#39;,
 &#39;adam&#39;,
 &#39;smith&#39;,
 &#39;contents&#39;,
 &#39;introduction&#39;,
 &#39;plan&#39;,
 &#39;work&#39;,
 &#39;book&#39;,
 &#39;causes&#39;,
 &#39;improvement&#39;,
 &#39;productive&#39;]
</pre></div>
</div>
</div>
</div>
<p>Having filtered the first entry, we can see that words such as ‘an’ and ‘into’ have disappeared but we have retained more informative words such as ‘inquiry’ and ‘nature’. Processing one entry is not enough: we need all of the lines to have stopwords removed. So we can now scale this up to the full corpus with <strong>pandas</strong>. Just as we did above, we’ll use a list comprehension to do this: but we’ll vectorise the list comprehension across the whole “tokens” series of our dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>an inquiry into the nature and causes of the ...</td>
      <td>[inquiry, nature, causes, wealth, nations, ada...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>powers of labour and of the order according to...</td>
      <td>[powers, labour, order, according, produce, na...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>distributed among the different ranks of the p...</td>
      <td>[distributed, among, different, ranks, people,...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>division of labour chapter iii that the divisi...</td>
      <td>[division, labour, chapter, iii, division, lab...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>the extent of the market chapter iv of the ori...</td>
      <td>[extent, market, chapter, iv, origin, use, mon...</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now we have a much reduced set of words in our tokens, which will make the next step of analysis more meaningful.</p>
</section>
<section id="counting-text">
<h2>Counting Text<a class="headerlink" href="#counting-text" title="Link to this heading">#</a></h2>
<p>There are several ways of performing basic counting statistics on text. We saw one in the previous chapter, <code class="docutils literal notranslate"><span class="pre">str.count()</span></code>, but that only applies to one word at a time. Often, we’re interested in the relative counts of words in a corpus. In this section, we’ll look at two powerful ways of computing this: using the <code class="docutils literal notranslate"><span class="pre">Counter()</span></code> function and via term frequenc-inverse document frequency.</p>
<p>First, <code class="docutils literal notranslate"><span class="pre">Counter()</span></code>, which is a built-in Python library that does pretty much what you’d expect. Here’s a simple example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="n">fruit_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;apple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;apple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="s2">&quot;satsuma&quot;</span><span class="p">,</span>
    <span class="s2">&quot;banana&quot;</span><span class="p">,</span>
    <span class="s2">&quot;orange&quot;</span><span class="p">,</span>
    <span class="s2">&quot;mango&quot;</span><span class="p">,</span>
    <span class="s2">&quot;satsuma&quot;</span><span class="p">,</span>
    <span class="s2">&quot;orange&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">fruit_list</span><span class="p">)</span>
<span class="n">freq</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter({&#39;orange&#39;: 3, &#39;apple&#39;: 2, &#39;satsuma&#39;: 2, &#39;banana&#39;: 1, &#39;mango&#39;: 1})
</pre></div>
</div>
</div>
</div>
<p>Counter returns a <code class="docutils literal notranslate"><span class="pre">collections.Counter</span></code> object where the numbers of each type in a given input list are summed. The resulting dictionary of unique counts can be extracted using <code class="docutils literal notranslate"><span class="pre">dict(freq)</span></code>, and <code class="docutils literal notranslate"><span class="pre">Counter()</span></code> has some other useful functions too including <code class="docutils literal notranslate"><span class="pre">most_common()</span></code> which, given a number <code class="docutils literal notranslate"><span class="pre">n</span></code>, returns <code class="docutils literal notranslate"><span class="pre">n</span></code> tuples of the form <code class="docutils literal notranslate"><span class="pre">(thing,</span> <span class="pre">count)</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;orange&#39;, 3), (&#39;apple&#39;, 2), (&#39;satsuma&#39;, 2), (&#39;banana&#39;, 1), (&#39;mango&#39;, 1)]
</pre></div>
</div>
</div>
</div>
<p>Say we wanted to apply this not just to every line in our corpus separately, but to our whole corpus in one go; how would we do it? <code class="docutils literal notranslate"><span class="pre">Counter()</span></code> will happily accept a list but our dataframe token column is currently a vector of lists. So we must first transform the token column to a single list of all tokens and then apply <code class="docutils literal notranslate"><span class="pre">Counter()</span></code>. To achieve the former and flatten a list of lists, we’ll use <code class="docutils literal notranslate"><span class="pre">itertools</span></code> chain function which makes an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the iterables in all inputs are exhausted. For example, given <code class="docutils literal notranslate"><span class="pre">[a,</span> <span class="pre">b,</span> <span class="pre">c]</span></code> and <code class="docutils literal notranslate"><span class="pre">[d,</span> <span class="pre">e,</span> <span class="pre">f]</span></code> as arguments, this function would return <code class="docutils literal notranslate"><span class="pre">[a,</span> <span class="pre">b,</span> <span class="pre">c,</span> <span class="pre">d,</span> <span class="pre">e,</span> <span class="pre">f]</span></code>. Because this function accepts an arbitrary number of iterable arguments, we use the splat operator, aka <code class="docutils literal notranslate"><span class="pre">*</span></code>, to tell it to expect lots of different arguments. The second step using <code class="docutils literal notranslate"><span class="pre">Counter()</span></code> is far more straightforward!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>

<span class="n">merged_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tokens&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()))</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">merged_list</span><span class="p">)</span>
<span class="n">freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;price&#39;, 775),
 (&#39;labour&#39;, 578),
 (&#39;quantity&#39;, 389),
 (&#39;greater&#39;, 386),
 (&#39;part&#39;, 376),
 (&#39;silver&#39;, 355),
 (&#39;one&#39;, 330),
 (&#39;much&#39;, 323),
 (&#39;upon&#39;, 322),
 (&#39;may&#39;, 313)]
</pre></div>
</div>
</div>
</div>
<p>Looking at the tuples representing the 10 most words in the corpus, there are some interesting patterns. “price” and “labour” are hardly surprises, while “silver” perhaps reflects the time in which the book was written a little more. “one”, “upon”, and “may” are candidates for context-specific stopwords; while our NLTK stopwords might work well for modern text, they omit words that were once more common but that are equally uninformative to the stopwords we did use. There’s no reason why these words couldn’t be added to our list of stopwords and the process re-run.</p>
<div class="admonition-exercise admonition">
<p class="admonition-title">Exercise</p>
<p>Extend the list of stopwords to include ‘may’, ‘upon’, ‘one’, and ‘much’, re-create the filtered tokens, and compute the 10 most common terms.</p>
</div>
</section>
<section id="sentence-tokenisation-and-reading-in-text-as-sentences">
<h2>Sentence Tokenisation (and reading in text as sentences)<a class="headerlink" href="#sentence-tokenisation-and-reading-in-text-as-sentences" title="Link to this heading">#</a></h2>
<p>So far we have been working with text that is split into lines and then tokenised into words. But working with lines of text is not always the most natural unit of analysis; sometimes sentences make more sense. So let’s now work with sentences and see an example of tokenising those.</p>
<p>First, we need to read in the text as sentences. We can’t do this with pandas, because that package is limited to tabular data or very simple delimiters (like commas).</p>
<p>If we were working with a local file on our computer, we could read it in using the following code</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;smith_won.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">raw_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
<p>As it is, the text file we’d like to grab is on the web so we’ll use a package that can grab files from the internet to get hold of it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/aeturrell/coding-for-economists/raw/main/data/smith_won.txt&quot;</span>
<span class="p">)</span>
<span class="n">raw_text</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span>
<span class="n">raw_text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;  An Inquiry into the Nature and Causes of the Wealth of Nations  by Adam Smith   Contents     INTRO&#39;
</pre></div>
</div>
</div>
</div>
<p>Great, so we have our raw text. Let’s now tokenise it using <strong>nltk</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk.tokenize</span><span class="w"> </span><span class="kn">import</span> <span class="n">sent_tokenize</span>

<span class="n">sent_list</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">df_sent</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">sent_list</span><span class="p">})</span>
<span class="n">df_sent</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>An Inquiry into the Nature and Causes of the...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BOOK I.</td>
    </tr>
    <tr>
      <th>2</th>
      <td>OF THE CAUSES OF IMPROVEMENT IN THE PRODUCTIVE...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CHAPTER I.</td>
    </tr>
    <tr>
      <th>4</th>
      <td>OF THE DIVISION OF LABOUR.</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now we just need to apply all of the cleaning procedures we did before——that is lowering the case, removing punctuation, and removing any excess whitespace.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_sent</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_sent</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">translator</span><span class="p">)</span>
    <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;\s+?\W+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">df_sent</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>an inquiry into the nature and causes of the ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>book i</td>
    </tr>
    <tr>
      <th>2</th>
      <td>of the causes of improvement in the productive...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>chapter i</td>
    </tr>
    <tr>
      <th>4</th>
      <td>of the division of labour</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We’ll use this tokenised version by sentence in the next section.</p>
<section id="tf-idf">
<h3>TF-IDF<a class="headerlink" href="#tf-idf" title="Link to this heading">#</a></h3>
<p>Term frequency - inverse document frequency, often referred to as <em>tf-idf</em>, is a measure of term counts (where terms could be 1-grams, 2-grams, etc.) that is weighted to try and identify the most <em>distinctively</em> frequent terms in a given corpus. It’s made up of two parts: a term-frequency (which upweights according to counts of terms) and an inverse document frequency (which downweights terms that appear frequently across the corpus). Define <span class="math notranslate nohighlight">\(t\)</span> as a term and <span class="math notranslate nohighlight">\(d\)</span> as a document. In our example thus far, <span class="math notranslate nohighlight">\(t\)</span> has represented words while our “documents” have been lines from <em>Wealth of Nations</em>. Then a simple formula for term frequency is:</p>
<div class="math notranslate nohighlight">
\[
{\displaystyle \mathrm {tf} (t,d)={\frac {f_{t,d}}{\sum _{t'\in d}{f_{t',d}}}}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(f_{t,d}\)</span> represents the frequency of term <span class="math notranslate nohighlight">\(t\)</span> in document <span class="math notranslate nohighlight">\(d\)</span>. To compute term frequencies, we will use the <a class="reference external" href="https://scikit-learn.org"><strong>sklearn</strong></a> package, which has a function called <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="n">stopwords</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The shape of the resulting tf matrix is </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()[</span><span class="mi">500</span><span class="p">:</span><span class="mi">510</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The shape of the resulting tf matrix is (7750, 5160)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;augustine&#39;, &#39;aulnagers&#39;, &#39;austria&#39;, &#39;authentic&#39;, &#39;authenticated&#39;,
       &#39;author&#39;, &#39;authorises&#39;, &#39;authority&#39;, &#39;authors&#39;, &#39;avail&#39;],
      dtype=object)
</pre></div>
</div>
</div>
</div>
<p>This created a matrix of 5,160 terms by 7,750 “documents” (actually sentences in our example) running with more or less the default settings. The only change we made to those default settings was to pass in a list of stopwords that we used earlier. The other default settings tokenise words using a regex of “(?u)\b\w\w+\b”, assume text is lowercase, only accept n-grams in the range (1, 1), and have no limit on the maximum number of features.</p>
<p>The matrix X that comes out is of an interesting type:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>scipy.sparse._csr.csr_matrix
</pre></div>
</div>
</div>
</div>
<p>ie, it’s a <em>sparse matrix</em>. Sparse matrices are more efficient for your computer when there are many missing zeros in a matrix. They do all of the usual things that matrices (arrays) do, but are just more convenient in this case. Most notably, we can perform counts with them and we can turn them into a regular matrix using <code class="docutils literal notranslate"><span class="pre">.toarray()</span></code>.</p>
<p>Let’s do some basic stats using the matrix of counts and the <strong>matplotlib</strong> visualisation library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">counts_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span><span class="o">.</span><span class="n">T</span>
<span class="n">counts_df</span> <span class="o">=</span> <span class="n">counts_df</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">counts_df</span> <span class="o">=</span> <span class="n">counts_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">counts_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>price       775
labour      578
quantity    389
greater     386
part        376
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot settings</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt&quot;</span>
<span class="p">)</span>


<span class="n">num_to_plot</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x_pos</span><span class="p">,</span> <span class="n">counts_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">counts_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Count of terms across all &quot;documents&quot;&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">num_to_plot</span><span class="si">}</span><span class="s2"> top 1-grams&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b5fb299c738a63e98de6a4d6351b329b0cc67b1b60b8c1d120beb51b5b009d68.svg" src="_images/b5fb299c738a63e98de6a4d6351b329b0cc67b1b60b8c1d120beb51b5b009d68.svg" />
</div>
</div>
<p>Let’s see what happens when we ask only for bi-grams.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Count bigrams:</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="n">stopwords</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">bigrams_df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Plot top n 2-grams</span>
<span class="n">num_to_plot</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x_pos</span><span class="p">,</span> <span class="n">bigrams_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">bigrams_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Count of terms across all &quot;documents&quot;&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">num_to_plot</span><span class="si">}</span><span class="s2"> top 2-grams&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9688e8e2d2e8c5803ea5ac4e7c10688f949146e9b363766d2f60d3280230b593.svg" src="_images/9688e8e2d2e8c5803ea5ac4e7c10688f949146e9b363766d2f60d3280230b593.svg" />
</div>
</div>
<p>As you might expect, the highest frequency with which 2-grams occur is less than the highest frequency with which 1-grams occur.</p>
<p>Now let’s move on to the inverse document frequency. The most common definition is</p>
<div class="math notranslate nohighlight">
\[
\mathrm{idf}(t, D) =  \log \frac{N}{|\{d \in D: t \in d\}|}
\]</div>
<p>where <span class="math notranslate nohighlight">\(D\)</span> is the set of documents, <span class="math notranslate nohighlight">\(N=|D|\)</span>, and  <span class="math notranslate nohighlight">\(|\{d \in D: t \in d\}|\)</span> is the number of documents in which <span class="math notranslate nohighlight">\(t\)</span> appears. Putting both together we have</p>
<div class="math notranslate nohighlight">
\[
\mathrm{tfidf}(t, d, D) = \mathrm{tf}(t, d) \cdot \mathrm{idf}(t, D)
\]</div>
<p>Because of power-law scaling, problems with zero-count entries, and other issues, this basic formula is often modified and the <a class="reference external" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">wikipedia page</a> for tf-idf gives a good run-down of some common options.</p>
<p>To perform tfidf with code, we’ll use another <strong>sklearn</strong> function, <code class="docutils literal notranslate"><span class="pre">TfidfVectorizer()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="n">stopwords</span><span class="p">,</span> <span class="n">sublinear_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="n">counts_tfidf</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
    <span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>
<span class="c1"># Plot top n 1-grams</span>
<span class="n">num_to_plot</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x_pos</span><span class="p">,</span> <span class="n">counts_tfidf</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">counts_tfidf</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;tf-idf weighted terms across all &quot;documents&quot;&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">num_to_plot</span><span class="si">}</span><span class="s2"> top 1-grams: tf-idf; X has shape </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b37f3c6f2ecf1e52b1cf17e627e6d9e249f4b66a582e61981510134a5ab1b4ab.svg" src="_images/b37f3c6f2ecf1e52b1cf17e627e6d9e249f4b66a582e61981510134a5ab1b4ab.svg" />
</div>
</div>
<p>There are small differences between this ranking of terms versus the original tf 1-gram version above. In the previous one, words such as ‘one’ were slightly higher in the ranking but their common appearance in multiple documents (lines) downweights them here. In this case, we also used the sublinear option, which uses <span class="math notranslate nohighlight">\(1+\log(\mathrm{tf})\)</span> in place of <span class="math notranslate nohighlight">\(\mathrm{tf}\)</span>.</p>
<section id="vector-inner-product-and-cosine-similarity">
<h4>Vector Inner Product and Cosine Similarity<a class="headerlink" href="#vector-inner-product-and-cosine-similarity" title="Link to this heading">#</a></h4>
<p>Because the output of tf or tf-idf is a matrix, many possibilities related to linear algebra are opened up. In particular, we can think of this the creation of a tf-idf matrix as defining a <span class="math notranslate nohighlight">\(|t| = T\)</span> dimensional vector space that is spanned by the term vectors (which act like basis vectors). Each document in the corpus then has a vector representation in terms of the basis vectors. A consequence is that there is a sensible inner vector product defined on the space. As a demonstration, let’s look for the line in the book that is closest to the title according to this vector space. The vector for the first line is just the first row in <span class="math notranslate nohighlight">\(X\)</span>. We take the argmax of the inner product with all of the <em>other</em> line vectors to find the entry in <code class="docutils literal notranslate"><span class="pre">X</span></code> that maximises the inner product.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_val</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>102
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Cosine similarity is </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">max_val</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_val</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sentence </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">sent</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cosine similarity is 0.42
Sentence 0:
	an inquiry into the nature and causes of the wealth of nations by adam smith contents introduction and plan of the work book i of the causes of improvement in the productive

Sentence 1:
	the society book i of the causes of improvement in the
</pre></div>
</div>
</div>
</div>
<p>We can see from this example <em>why</em> the sentence we found is the most similar in the book to the title: it contains a phrase that is very similar to part of the title. It’s worth noting here that tf-idf (and tf) do not care about <em>word order</em>, they only care about frequency, and so sometimes the most similar sentences are not what you would expect if you were judging similarity based on concepts. Another way of saying this is that the concept of ‘similarity’ as used by tf-idf is limited.</p>
</section>
<section id="transform-versus-fit-transform">
<h4>Transform versus Fit Transform<a class="headerlink" href="#transform-versus-fit-transform" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> function we’ve seen is actually performing two operations here: i) create a vector space from the basis defined by terms from the text and ii) express each document (here, a sentence) as a vector in this vector space. But there’s no reason why these two operations have to be linked. In fact, by separating out these two operations, we can do nifty things like express one text in the basis vectors of another. This is more useful in practice than you might think. It allows you to ask questions like, “which of the texts in my reference corpus is most closest to these other texts?”, and more. We would ask this question by taking the inner vector product of the matrices expressing the two corpora, and find the rows of Wealth of Nations that have the greatest cosine similarity with the other texts.</p>
<p>Let’s see an example, with some test texts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;poverty is a trap and rearing children in it is hard and perilous&quot;</span><span class="p">,</span>
            <span class="s2">&quot;people in different trades can meet and develop a conspiracy which ultimately hurts consumers by raising prices&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we need to i) create the vector space, ii) express WoN in the vector space, iii) express the test texts in the vector space, iv) find which rows of the WoN match best the test texts, and v) print out those rows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="n">stopwords</span><span class="p">,</span> <span class="n">sublinear_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># i)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_sent</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="c1"># ii)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_sent</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="c1"># iii)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="c1"># iv)</span>
<span class="n">max_index_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">max_index_pos</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1012, 1768]
</pre></div>
</div>
</div>
</div>
<p>Now, armed with the rows of <span class="math notranslate nohighlight">\(X\)</span>, we are ready for the final part, v)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">y_pos</span><span class="p">,</span> <span class="n">x_pos</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">max_index_pos</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sentence number </span><span class="si">{</span><span class="n">y_pos</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;        test: </span><span class="si">{</span><span class="n">df_test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y_pos</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;         WoN: </span><span class="si">{</span><span class="n">df_sent</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">x_pos</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sentence number 0:
        test: poverty is a trap and rearing children in it is hard and perilous
         WoN: but poverty though it does not prevent the generation is extremely unfavourable to the rearing of children 

Sentence number 1:
        test: people in different trades can meet and develop a conspiracy which ultimately hurts consumers by raising prices
         WoN: people of the same trade seldom meet together even for merriment and diversion but the conversation ends in a conspiracy against the public or in some contrivance to raise prices 
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-a-special-vocabulary">
<h4>Using a Special Vocabulary<a class="headerlink" href="#using-a-special-vocabulary" title="Link to this heading">#</a></h4>
<p>But why should the basis vectors come from the terms in another text? Couldn’t they come from anywhere? The answer is, of course, yes. We could choose any set of basis vectors we liked to define our vector space, and express a text in it. For this, we need a <em>special vocabulary</em>.</p>
<p>Let’s see an example of expressing the Wealth of Nations in a particularly vocab. First, we must define our vocab:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;work&quot;</span><span class="p">,</span> <span class="s2">&quot;wage&quot;</span><span class="p">,</span> <span class="s2">&quot;labour&quot;</span><span class="p">,</span> <span class="s2">&quot;real price&quot;</span><span class="p">,</span> <span class="s2">&quot;money price&quot;</span><span class="p">,</span> <span class="s2">&quot;productivity&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>That done, we now plug our special vocab into <code class="docutils literal notranslate"><span class="pre">CountVectorizer()</span></code> to tell it to ignore anything that isn’t relevant (isn’t in our vocab).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">vocabulary</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">counts_df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_sent</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Plot counts from our vocab</span>
<span class="n">num_to_plot</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">x_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">x_pos</span><span class="p">,</span> <span class="n">counts_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">x_pos</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">counts_df</span><span class="p">[:</span><span class="n">num_to_plot</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Count of terms in corpus&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Counts of vocab words in the Wealth of Nations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/67b19b691714cd6c0802d1098a3c52396d50e397dcfbb01e50cbf629e5128f48.svg" src="_images/67b19b691714cd6c0802d1098a3c52396d50e397dcfbb01e50cbf629e5128f48.svg" />
</div>
</div>
<p>Note that we did not pass <code class="docutils literal notranslate"><span class="pre">stopwords</span></code> in this case; there’s no need, because passing a <code class="docutils literal notranslate"><span class="pre">vocab</span></code> effectively says to categorise any word that is <em>not</em> in the special vocabulary as a stopword. We also still passed an n-gram range to ensure our longest n-gram, with <span class="math notranslate nohighlight">\(n=2\)</span>, was counted.</p>
</section>
</section>
<section id="filtering-out-frequent-and-infrequent-words">
<h3>Filtering Out Frequent and Infrequent Words<a class="headerlink" href="#filtering-out-frequent-and-infrequent-words" title="Link to this heading">#</a></h3>
<p>As well as passing stopwords in, defining vocabularies, and limiting the n-gram range, there’s another couple of ways to cut down on the number of terms that tf-idf takes account of. The first is to use the <code class="docutils literal notranslate"><span class="pre">max_features</span></code> setting to limit how many terms are tracked (this only keeps the top terms). A second is to have frequency cut-offs, both for very frequent words and for very infrequent words (be careful of this one if you’re doing any kind of out-of-sample exercise such as forecasting.) The keywords for frequency cut-offs are <code class="docutils literal notranslate"><span class="pre">max_df</span></code> and <code class="docutils literal notranslate"><span class="pre">min_df</span></code>.</p>
</section>
</section>
<section id="context-of-terms">
<h2>Context of Terms<a class="headerlink" href="#context-of-terms" title="Link to this heading">#</a></h2>
<p>It’s all very well counting terms, but without the context of the surrounding words, it may not be all that informative. <strong>nltk</strong> has some functions that can help us. First, we have to pass our raw text into an <strong>nltk</strong> text object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">Text</span>

<span class="n">w_o_n</span> <span class="o">=</span> <span class="n">Text</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">raw_text</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s imagine we’re interested in the context of a particular term, say ‘price’. We can run:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_o_n</span><span class="o">.</span><span class="n">concordance</span><span class="p">(</span><span class="s2">&quot;price&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Displaying 25 of 775 matches:
. CHAPTER V. OF THE REAL AND NOMINAL PRICE OF COMMODITIES , OR OF THEIR PRICE I
L PRICE OF COMMODITIES , OR OF THEIR PRICE IN LABOUR , AND THEIR PRICE IN MONEY
OF THEIR PRICE IN LABOUR , AND THEIR PRICE IN MONEY . CHAPTER VI . OF THE COMPO
ER VI . OF THE COMPONENT PART OF THE PRICE OF COMMODITIES . CHAPTER VII . OF TH
PTER VII . OF THE NATURAL AND MARKET PRICE OF COMMODITIES . CHAPTER VIII . OF T
 in most years nearly about the same price with the corn of England , though , 
at comes to the same thing , for the price of a great quantity of theirs . He s
one to the other , except such whose price was very considerable in proportion 
value ; or wherein consists the real price of all commodities . Secondly , what
e different parts of which this real price is composed or made up . And , lastl
e or all of these different parts of price above , and sometimes sink them belo
es which sometimes hinder the market price , that is , the actual price of comm
 market price , that is , the actual price of commodities , from coinciding exa
ith what may be called their natural price . I shall endeavour to explain , as 
. CHAPTER V. OF THE REAL AND NOMINAL PRICE OF COMMODITIES , OR OF THEIR PRICE I
L PRICE OF COMMODITIES , OR OF THEIR PRICE IN LABOUR , AND THEIR PRICE IN MONEY
OF THEIR PRICE IN LABOUR , AND THEIR PRICE IN MONEY . Every man is rich or poor
 value of all commodities . The real price of every thing , what every thing re
qual quantity . Labour was the first price , the original purchase money that w
is liberty , and his happiness . The price which he pays must always be the sam
ated and compared . It is their real price ; money is their nominal price only 
 real price ; money is their nominal price only . But though equal quantities o
r quantity of goods , and to him the price of labour seems to vary like that of
be said to have a real and a nominal price . Its real price may be said to cons
 real and a nominal price . Its real price may be said to consist in the quanti
</pre></div>
</div>
</div>
</div>
<p>This gives us context for all fo the occurrences of the terms. Context is useful, but there’s more than one kind. What about <em>where</em> in a text references to different ideas or terms appear? We can do that with  <em>text dispersion plot</em>, as shown below for a selection of terms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_o_n</span><span class="o">.</span><span class="n">dispersion_plot</span><span class="p">([</span><span class="s2">&quot;price&quot;</span><span class="p">,</span> <span class="s2">&quot;labour&quot;</span><span class="p">,</span> <span class="s2">&quot;production&quot;</span><span class="p">,</span> <span class="s2">&quot;America&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2e63aa3a0d7f6250d4f823ae6133208839ed22646684f0736eb86a6c14088d93.svg" src="_images/2e63aa3a0d7f6250d4f823ae6133208839ed22646684f0736eb86a6c14088d93.svg" />
</div>
</div>
</section>
<section id="stemming-and-lemmatisation">
<h2>Stemming and Lemmatisation<a class="headerlink" href="#stemming-and-lemmatisation" title="Link to this heading">#</a></h2>
<p>You may have wondered, in these examples, what about words that mean the same but have different endings, for example “work”, “working”,  “worked”, and “works”? In most of the examples shown, we’ve only counted one of these words and thereby could <em>underestimate</em> their presence. If what we really want to do is capture all discussion of a topic like ‘work’,  we should really be counting every variation on the word representing that topic.</p>
<p><em>Stemming</em> is a way to do this because it takes the stem of all of these words, in this example “work”, and then counts the stems. It’s true that this is sometimes a bit more nonsensical than using the original word (think “sci” for “science”, “scientist”, and “scientific”) but it can give a more accurate take on the occurrence of a term.</p>
<p><strong>nltk</strong> includes more than one stemmer to reduce words to their roots. Let’s see what happens when we take the tokenised words and stem them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">LancasterStemmer</span>

<span class="c1"># create an object of class LancasterStemmer</span>
<span class="n">lancaster</span> <span class="o">=</span> <span class="n">LancasterStemmer</span><span class="p">()</span>

<span class="n">cleaner_text</span> <span class="o">=</span> <span class="n">raw_text</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">translator</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="n">stem_tokens</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">lancaster</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">term</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">cleaner_text</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">term</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
<span class="p">]</span>
<span class="n">stem_tokens</span><span class="p">[</span><span class="mi">120</span><span class="p">:</span><span class="mi">135</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;iv&#39;,
 &#39;stock&#39;,
 &#39;lent&#39;,
 &#39;interest&#39;,
 &#39;chapt&#39;,
 &#39;v&#39;,
 &#39;diff&#39;,
 &#39;employ&#39;,
 &#39;capit&#39;,
 &#39;book&#39;,
 &#39;ii&#39;,
 &#39;diff&#39;,
 &#39;progress&#39;,
 &#39;op&#39;,
 &#39;diff&#39;]
</pre></div>
</div>
</div>
</div>
<p>Now we have “pric” instead of price, and “compon” instead of “compnonent”, and so on. The stemming has taken away the ends of the words, leaving us with just their stem. Let’s see if a word count following this approach will be different.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">stem_tokens</span><span class="p">)</span>
<span class="n">freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;pric&#39;, 832),
 (&#39;gre&#39;, 700),
 (&#39;labo&#39;, 686),
 (&#39;part&#39;, 511),
 (&#39;quant&#39;, 442),
 (&#39;country&#39;, 388),
 (&#39;produc&#39;, 356),
 (&#39;silv&#39;, 355),
 (&#39;diff&#39;, 348),
 (&#39;on&#39;, 348)]
</pre></div>
</div>
</div>
</div>
<p>In this case, the words that are most frequent are much the same: but you can imagine this could easily have <em>not</em> been the case and, if you’re interested in fully capturing a topic, it’s a good idea to at least check a stemmed version for comparison.</p>
<p><em>Lemmatisation</em> is slightly different; it’s a bit more intelligent than just chopping off the end of the word because it considers context and converts a word to a base form, called a lemma. Let’s perform the same exercise using lemmatisation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">WordNetLemmatizer</span>

<span class="c1"># create an object of class LancasterStemmer</span>
<span class="n">wnet_lemma</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>

<span class="n">lemma_tokens</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">wnet_lemma</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">term</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">cleaner_text</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">term</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span>
<span class="p">]</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">lemma_tokens</span><span class="p">)</span>
<span class="n">freq</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;price&#39;, 832),
 (&#39;labour&#39;, 578),
 (&#39;part&#39;, 475),
 (&#39;quantity&#39;, 442),
 (&#39;country&#39;, 388),
 (&#39;greater&#39;, 386),
 (&#39;silver&#39;, 355),
 (&#39;one&#39;, 347),
 (&#39;time&#39;, 343),
 (&#39;much&#39;, 323)]
</pre></div>
</div>
</div>
</div>
<p>The lemmatised words we’re dealing with are more <em>understandable</em> than in the case of stemming, but note that the top ten most frequent words have changed a little too.</p>
</section>
<section id="part-of-speech-tagging">
<h2>Part of Speech Tagging<a class="headerlink" href="#part-of-speech-tagging" title="Link to this heading">#</a></h2>
<p>Sentences are made up of verbs, nouns, adjectives, pronouns, and more of the building blocks of language. Sometimes, when you’re doing text analysis, it’s useful to understand and extract only some so-called parts of speech (or PoS). The NLP tools we’ve already seen can help us to do that. In the example below, we’ll use <code class="docutils literal notranslate"><span class="pre">pos_tag</span></code> to tag the different parts of speech in a sentence of tokenised text. The function returns tuples of ‘(word, part-of-speech)’ that we can print out.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may need to run <code class="docutils literal notranslate"><span class="pre">nltk.download('averaged_perceptron_tagger')</span></code> to use the <code class="docutils literal notranslate"><span class="pre">pos_tag</span></code> function.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk</span><span class="w"> </span><span class="kn">import</span> <span class="n">pos_tag</span>

<span class="n">example_sent</span> <span class="o">=</span> <span class="s2">&quot;If we are going to die, let us die looking like a Peruvian folk band.&quot;</span>

<span class="n">pos_tagged_words</span> <span class="o">=</span> <span class="n">pos_tag</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">example_sent</span><span class="p">))</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">pos_tagged_words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The word &quot;</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s1">&quot; is a </span><span class="si">{</span><span class="n">pos</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The word &quot;If&quot; is a IN
The word &quot;we&quot; is a PRP
The word &quot;are&quot; is a VBP
The word &quot;going&quot; is a VBG
The word &quot;to&quot; is a TO
The word &quot;die&quot; is a VB
The word &quot;let&quot; is a VB
The word &quot;us&quot; is a PRP
The word &quot;die&quot; is a VB
The word &quot;looking&quot; is a VBG
The word &quot;like&quot; is a IN
The word &quot;a&quot; is a DT
The word &quot;Peruvian&quot; is a JJ
The word &quot;folk&quot; is a NN
The word &quot;band&quot; is a NN
</pre></div>
</div>
</div>
</div>
<p><strong>nltk</strong> uses contractions to refer to the different parts of speech: IN is a preposition, PRP a personal pronoun, VBP a verb (in non 3rd person singular present), JJ is an adjective, NN a noun, and so on.</p>
<p>When might you actually use PoS tagging? You can imagine thinking about how the use of language is different or has changed across people or institutions. You might be interested in how more active language is being employed to help readers engage more with documents and reports issued by official organisations. You might be interested in removing all words that aren’t, for example, nouns before doing some further analysis.</p>
<p>When it comes to PoS tagging, <strong>nltk</strong> is far from the only option. Another very powerful NLP library, <a class="reference external" href="https://spacy.io/"><strong>spacy</strong></a> definitely warrants a mention. Like <strong>nltk</strong>, <strong>spacy</strong> requires you to install add-ons called models to perform extra tasks. To install <strong>spacy</strong>, it’s <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">spacy</span></code> and to load the most commonly used model it’s <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">spacy</span> <span class="pre">download</span> <span class="pre">en_core_web_sm</span></code>, both to be run on the command line.</p>
<p>Let’s see the same PoS example but in <strong>spacy</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>

<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">example_sent</span><span class="p">)</span>

<span class="n">pos_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">lemma_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">tag_</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;lemma&quot;</span><span class="p">,</span> <span class="s2">&quot;pos&quot;</span><span class="p">,</span> <span class="s2">&quot;tag&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">pos_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>lemma</th>
      <th>pos</th>
      <th>tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>If</td>
      <td>if</td>
      <td>SCONJ</td>
      <td>IN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>we</td>
      <td>we</td>
      <td>PRON</td>
      <td>PRP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>are</td>
      <td>be</td>
      <td>AUX</td>
      <td>VBP</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>folk</td>
      <td>folk</td>
      <td>NOUN</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>15</th>
      <td>band</td>
      <td>band</td>
      <td>NOUN</td>
      <td>NN</td>
    </tr>
    <tr>
      <th>16</th>
      <td>.</td>
      <td>.</td>
      <td>PUNCT</td>
      <td>.</td>
    </tr>
  </tbody>
</table>
<p>17 rows × 4 columns</p>
</div></div></div>
</div>
<p>For those brave enough for the pun, <strong>spacy</strong> also has some nifty visualisation tools.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">spacy</span><span class="w"> </span><span class="kn">import</span> <span class="n">displacy</span>

<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;When you light a candle, you also cast a shadow.&quot;</span><span class="p">)</span>

<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;dep&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" id="5ec76cee29a2493e88871d8c6400b7a3-0" class="displacy" width="1800" height="399.5" direction="ltr" style="max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr">
<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="50">When</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="50">SCONJ</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="225">you</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="225">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="400">light</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="400">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="575">a</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="575">DET</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="750">candle,</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="750">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="925">you</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="925">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="1100">also</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1100">ADV</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="1275">cast</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1275">VERB</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="1450">a</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1450">DET</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="309.5">
    <tspan class="displacy-word" fill="currentColor" x="1625">shadow.</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="1625">NOUN</tspan>
</text>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-0" stroke-width="2px" d="M70,264.5 C70,89.5 395.0,89.5 395.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-0" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">advmod</textPath>
    </text>
    <path class="displacy-arrowhead" d="M70,266.5 L62,254.5 78,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-1" stroke-width="2px" d="M245,264.5 C245,177.0 390.0,177.0 390.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-1" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textPath>
    </text>
    <path class="displacy-arrowhead" d="M245,266.5 L237,254.5 253,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-2" stroke-width="2px" d="M420,264.5 C420,2.0 1275.0,2.0 1275.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-2" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">advcl</textPath>
    </text>
    <path class="displacy-arrowhead" d="M420,266.5 L412,254.5 428,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-3" stroke-width="2px" d="M595,264.5 C595,177.0 740.0,177.0 740.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-3" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">det</textPath>
    </text>
    <path class="displacy-arrowhead" d="M595,266.5 L587,254.5 603,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-4" stroke-width="2px" d="M420,264.5 C420,89.5 745.0,89.5 745.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-4" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textPath>
    </text>
    <path class="displacy-arrowhead" d="M745.0,266.5 L753.0,254.5 737.0,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-5" stroke-width="2px" d="M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-5" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textPath>
    </text>
    <path class="displacy-arrowhead" d="M945,266.5 L937,254.5 953,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-6" stroke-width="2px" d="M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-6" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">advmod</textPath>
    </text>
    <path class="displacy-arrowhead" d="M1120,266.5 L1112,254.5 1128,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-7" stroke-width="2px" d="M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-7" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">det</textPath>
    </text>
    <path class="displacy-arrowhead" d="M1470,266.5 L1462,254.5 1478,254.5" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-5ec76cee29a2493e88871d8c6400b7a3-0-8" stroke-width="2px" d="M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-5ec76cee29a2493e88871d8c6400b7a3-0-8" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">dobj</textPath>
    </text>
    <path class="displacy-arrowhead" d="M1620.0,266.5 L1628.0,254.5 1612.0,254.5" fill="currentColor"/>
</g>
</svg></span></div></div>
</div>
</section>
<section id="named-entity-recognition">
<h2>Named Entity Recognition<a class="headerlink" href="#named-entity-recognition" title="Link to this heading">#</a></h2>
<p>This is another NLP tool that helps to pick apart the parts of language, in this case it’s a method for extracting all of the entities named in a text, whether they be people, countries, cars, whatever.</p>
<p>Let’s see an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;TAE Technologies, a California-based firm building technology to generate power from nuclear fusion, said on Thursday it had raised $280 million from new and existing investors, including Google and New Enterprise Associates.&quot;</span>

<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    TAE Technologies
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
, a 
<mark class="entity" style="background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    California
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">GPE</span>
</mark>
-based firm building technology to generate power from nuclear fusion, said on 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Thursday
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 it had raised 
<mark class="entity" style="background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    $280 million
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">MONEY</span>
</mark>
 from new and existing investors, including 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 and 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    New Enterprise Associates
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
.</div></span></div></div>
</div>
<p>Pretty impressive stuff, but a health warning that there are plenty of texts that are not quite as clean as this one! As with the PoS tagger, you can extract the named entities in a tabular format for onward use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">start_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">end_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;start_pos&quot;</span><span class="p">,</span> <span class="s2">&quot;end_pos&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>start_pos</th>
      <th>end_pos</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>TAE Technologies</td>
      <td>0</td>
      <td>16</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>1</th>
      <td>California</td>
      <td>20</td>
      <td>30</td>
      <td>GPE</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Thursday</td>
      <td>109</td>
      <td>117</td>
      <td>DATE</td>
    </tr>
    <tr>
      <th>3</th>
      <td>$280 million</td>
      <td>132</td>
      <td>144</td>
      <td>MONEY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Google</td>
      <td>188</td>
      <td>194</td>
      <td>ORG</td>
    </tr>
    <tr>
      <th>5</th>
      <td>New Enterprise Associates</td>
      <td>199</td>
      <td>224</td>
      <td>ORG</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The table below gives the different label meanings in Named Entity Recognition:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Label</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>geo</p></td>
<td><p>Geographical entity</p></td>
</tr>
<tr class="row-odd"><td><p>org</p></td>
<td><p>Organisation</p></td>
</tr>
<tr class="row-even"><td><p>per</p></td>
<td><p>Person</p></td>
</tr>
<tr class="row-odd"><td><p>gpe</p></td>
<td><p>Geopolitical entity</p></td>
</tr>
<tr class="row-even"><td><p>date</p></td>
<td><p>Time indicator</p></td>
</tr>
<tr class="row-odd"><td><p>art</p></td>
<td><p>Artifact</p></td>
</tr>
<tr class="row-even"><td><p>eve</p></td>
<td><p>Event</p></td>
</tr>
<tr class="row-odd"><td><p>nat</p></td>
<td><p>Natural phenomenon</p></td>
</tr>
<tr class="row-even"><td><p>money</p></td>
<td><p>Reference to money amount</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="readability-statistics">
<h2>Readability Statistics<a class="headerlink" href="#readability-statistics" title="Link to this heading">#</a></h2>
<p>Like them or loathe them, readability statistics are widely used despite what flaws individual approaches may have. Let’s take a look at at a package that can compute a wide range of them, <a class="reference external" href="https://github.com/shivam5992/textstat"><strong>textstat</strong></a>. We’ll see what it can do with English, but it supports other languages too. And we won’t use all of its measures, just a few of the most well-known.</p>
<p>As ever, you will need to run <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">textstat</span></code> on the command line if you don’t already have this package installed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">textstat</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Playing games has always been thought to be important to &quot;</span>
    <span class="s2">&quot;the development of well-balanced and creative children; &quot;</span>
    <span class="s2">&quot;however, what part, if any, they should play in the lives &quot;</span>
    <span class="s2">&quot;of adults has never been researched that deeply. I believe &quot;</span>
    <span class="s2">&quot;that playing games is every bit as important for adults &quot;</span>
    <span class="s2">&quot;as for children. Not only is taking time out to play games &quot;</span>
    <span class="s2">&quot;with our children and other adults valuable to building &quot;</span>
    <span class="s2">&quot;interpersonal relationships but is also a wonderful way &quot;</span>
    <span class="s2">&quot;to release built up tension.&quot;</span>
<span class="p">)</span>

<span class="n">stat_func_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">textstat</span><span class="o">.</span><span class="n">flesch_reading_ease</span><span class="p">,</span>
    <span class="n">textstat</span><span class="o">.</span><span class="n">flesch_kincaid_grade</span><span class="p">,</span>
    <span class="n">textstat</span><span class="o">.</span><span class="n">automated_readability_index</span><span class="p">,</span>
    <span class="n">textstat</span><span class="o">.</span><span class="n">dale_chall_readability_score</span><span class="p">,</span>
    <span class="n">textstat</span><span class="o">.</span><span class="n">difficult_words</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[[</span><span class="n">fn</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">stat_func_names</span><span class="p">]],</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">stat_func_names</span><span class="p">],</span>
    <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">],</span>
<span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>flesch_reading_ease</th>
      <td>43.77</td>
    </tr>
    <tr>
      <th>flesch_kincaid_grade</th>
      <td>13.90</td>
    </tr>
    <tr>
      <th>automated_readability_index</th>
      <td>15.50</td>
    </tr>
    <tr>
      <th>dale_chall_readability_score</th>
      <td>7.30</td>
    </tr>
    <tr>
      <th>difficult_words</th>
      <td>11.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Link to this heading">#</a></h2>
<p>We’ve only scratched the surface of NLP here; there are many other libraries and methods out there. A good easy-to-use introductory NLP package that we didn’t feature is <a class="reference external" href="https://textblob.readthedocs.io/en/dev/"><strong>textblob</strong></a>. In terms of methods, we haven’t looked at noun phrase extraction or spelling correction-but <strong>textblob</strong> offers both of these.</p>
</section>
<section id="review">
<h2>Review<a class="headerlink" href="#review" title="Link to this heading">#</a></h2>
<p>This chapter has provided an overview of some common methods in natural language processing. If you’ve worked through this chapter, you should now be comfortable:</p>
<ul class="simple">
<li><p>✅ splitting text into lines or sentences;</p></li>
<li><p>✅ tokenising text;</p></li>
<li><p>✅ removing stopwords from text;</p></li>
<li><p>✅ computing tf-idf matrices and using the vector spaces that they create for simple similarity calculations;</p></li>
<li><p>✅ disentangling the different parts of speech, including any named entities;</p></li>
<li><p>✅ stemming and lemmatising text; and</p></li>
<li><p>✅ computing statistics on the readability of text.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="text-regex.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Regular Expressions, aka regex</p>
      </div>
    </a>
    <a class="right-next"
       href="ml-intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Machine Learning and AI</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation">Tokenisation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-with-regular-expressions">Tokenisation with regular expressions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenisation-using-nlp-tools">Tokenisation using NLP tools</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#removing-stop-words">Removing Stop Words</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#counting-text">Counting Text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentence-tokenisation-and-reading-in-text-as-sentences">Sentence Tokenisation (and reading in text as sentences)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-idf">TF-IDF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-inner-product-and-cosine-similarity">Vector Inner Product and Cosine Similarity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transform-versus-fit-transform">Transform versus Fit Transform</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-a-special-vocabulary">Using a Special Vocabulary</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-out-frequent-and-infrequent-words">Filtering Out Frequent and Infrequent Words</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#context-of-terms">Context of Terms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stemming-and-lemmatisation">Stemming and Lemmatisation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-of-speech-tagging">Part of Speech Tagging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#readability-statistics">Readability Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#see-also">See Also</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#review">Review</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Arthur Turrell
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  This book is available under an MIT license.
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>