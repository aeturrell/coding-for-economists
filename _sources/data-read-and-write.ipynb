{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d519f80d",
   "metadata": {},
   "source": [
    "(data-read-and-write)=\n",
    "# Reading and Writing Files\n",
    "\n",
    "In this chapter, you'll learn about reading and writing data.\n",
    "\n",
    "This chapter uses the **pandas** package. If you're running this code, you may need to install these packages using, for example, `pip install packagename` on your computer's command line. (If you're not sure what a command line or terminal is, take a quick look at the basics of coding chapter.)\n",
    "\n",
    "![From the pandas documentation](https://pandas.pydata.org/pandas-docs/stable/_images/02_io_readwrite.svg)\n",
    "\n",
    "There are a huge range of input and output formats available in **pandas**: Stata (.dta), Excel (.xls, .xlsx), csv (tab or comma or whatever, use the `sep=` keyword), big data formats (HDF5, parquet), JSON, SAS, SPSS, SQL, and more; there's a [full list](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) of formats available in the documentation.\n",
    "\n",
    "Let's set some preliminary settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38160e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set pandas max rows displayed for readability\n",
    "pd.set_option('display.max_rows', 6)\n",
    "# Plot settings\n",
    "plt.style.use(\"https://github.com/aeturrell/coding-for-economists/raw/main/plot_style.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066bf85",
   "metadata": {},
   "source": [
    "## Reading in data from a file\n",
    "\n",
    "The syntax for reading in data is usually very similar and of the form `pd.read_` and then the format e.g. `df = pd.read_stata('statafile.dta')` for Stata. And here's a typical example of reading a csv file\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "```\n",
    "\n",
    "These examples assume that the data file is in the *working directory* of the Python console, but what if it's not?\n",
    "\n",
    "If the data are not in working directory, you need to add information about the relative path to the file. Let's say the data were in a folder called 'data' in another folder called 'files'. Different operating systems have different file path conventions: on a Mac or Linux machine, you would open this file using `df = pd.read_stata('files/data/statafile.dta')` but, on Windows, the slashes go the other way. If you're writing code to be *reproducible* you should endeavour, insofar as you can, to make it run happily on all major operating systems. Fortunately, the built-in **pathlib** package can help out with this.\n",
    "\n",
    "Here's a really typical example of reading in a csv called 'data.csv' whose relative path to the working directory of the code is a folder 'research' and then 'files':\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(Path('research/files/data.csv'))\n",
    "```\n",
    "\n",
    "**pathlib** takes care of paths on different operating systems: it doesn't mind you using forward slashes, even on Windows, because it will translate the relative path you have entered into whatever the local operating system needs. There are introductory videos to **pathlib** and its use available [here](https://calmcode.io/pathlib/do-not-hardcode.html).\n",
    "\n",
    "### Reading data from lots of files\n",
    "\n",
    "Quite often, you have a case where you need to read in data from many files at once. There are two tools that will help with this: glob and concatenate.\n",
    "\n",
    "Imagine you have a directory full of files with names like 'Jan-2001-data.csv', 'Feb-2001-data.csv', and so on. The `glob()` command can help you grab the names of all of these files. Imagine your files are in 'research/data', then you would use:\n",
    "\n",
    "```python\n",
    "p = Path(\"research/data\")\n",
    "list_of_files = list(p.glob('*-data.csv'))\n",
    "```\n",
    "\n",
    "Here, the `*` character is a wildcard that can match to anything (including any number of characters). You can keep it more specific by, for example, searching for a single wildcard character with `?` or any single digit with `[0-9]`.\n",
    "\n",
    "Okay, so you have a big list of file paths: now what!? Assuming that the files have the same structure (eg the same columns), we can use `pd.read_csv()` in a list followed by `pd.concat()` to collapse these down either by index or by column (typically it's by index):\n",
    "\n",
    "```python\n",
    "df = pd.concat([pd.read_csv(x) for x in list_of_files], axis=0)\n",
    "```\n",
    "\n",
    "## Writing data to file\n",
    "\n",
    "The syntax for writing to a file is also very consistent, taking the form `df.to_*()` where `*` might be `csv`, `stata`, or a number of output formats (you can even output to your computer's clipboard!).\n",
    "\n",
    "In general, you *do* need to specify the file extension though, i.e. when saving data you should specify `df.to_csv('dataout.csv')` rather than `df.to_csv('dataout')`. As with reading in, there are plenty of options for how to output data, and you can find more on outputs in the **pandas** [documentation](https://pandas.pydata.org/docs/user_guide/io.html).\n",
    "\n",
    "### Formats\n",
    "\n",
    "You may wonder what file format to use in your work. Note that data formats differ in whether they are text based (csv, JSON) or binary (encoded and compressed, like Python's pickle format). The former tend to be more easy to use with a range of tools, while the latter are usually faster to read/write and take up less space on disk.\n",
    "\n",
    "There's a lot to be said for plain old csv because it's interoperable between so many different software tools. I highly recommend it for your final results, if they will be shared. Its only trouble is that it's not very efficiency with space, and it's not 'intelligent' about column datatypes. If you want a format for intermediate data within a project, I tend to recommend parquet, which scales well to big data (it is very efficient with disk space) and has excellent read and write speeds. Feather is interoperable between Python and R and may also be a good choice. Depending on the structure of your data, you may find JSON a good option too.\n",
    "\n",
    "If you're interested in how effective the different data formats are, there blog posts that address this question [here](https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d) and [here](https://ursalabs.org/blog/2019-10-columnar-perf/).\n",
    "\n",
    "It's best *not* to use formats associated with proprietary software, especially if the standard may change over time (Stata files change with the version of Stata used!!) or if opening the data in that tool might change it (hello Excel). It's also good practice *not* to use a data storage format that cannot easily be opened by other tools. For this reason, I don't generally recommend Python's pickle format or R's RDA format (though of course it's fine if your data is completely internal to your project and you're only using one language).\n",
    "\n",
    "## Reading and writing text, tex, md, and other text-editor friendly file formats\n",
    "\n",
    "It's frequently the case that you'll want to write an individual table, chunk of text, or other content that can be opened with a text editor to file. **pandas** has some convenience functions for this (there was a short example in the data analysis quickstart). Let's say we had a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41401d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.857143</td>\n",
       "      <td>992.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.863636</td>\n",
       "      <td>998.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.174129</td>\n",
       "      <td>1003.875622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.325685</td>\n",
       "      <td>991.592416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49.410256</td>\n",
       "      <td>992.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.542453</td>\n",
       "      <td>997.877358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            wind     pressure\n",
       "month                        \n",
       "1      49.857143   992.400000\n",
       "4      38.863636   998.121212\n",
       "5      35.174129  1003.875622\n",
       "...          ...          ...\n",
       "10     51.325685   991.592416\n",
       "11     49.410256   992.266667\n",
       "12     45.542453   997.877358\n",
       "\n",
       "[10 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv')\n",
    "table = (df.groupby(['month'])\n",
    "           .agg({'wind': 'mean',\n",
    "                 'pressure': 'mean'}))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96bb00",
   "metadata": {},
   "source": [
    "Our options for export of the `table` variable (which has datatype `pandas.core.frame.DataFrame`) are varied. For instance, we could use\n",
    "\n",
    "```python\n",
    "table.to_markdown()\n",
    "```\n",
    "\n",
    "to create data suitable for putting in a markdown file, `table.to_string()` to get plain text, and `table.style.latex()` for latex (note that latex output includes the `.style` part). There's even a `table.to_html()`!\n",
    "\n",
    "Each of these export options accepts a filepath to write to, eg one can write `table.style.to_latex(os.path.join('path', 'to', 'file.md'))`.\n",
    "\n",
    "```{note}\n",
    "`.to_markdown()` has a dependency on another package, [**tabulate**](https://github.com/astanin/python-tabulate), which is for pretty-printing tables in Python and on the command line. You can install it using `pip install tabulate`.\n",
    "```\n",
    "\n",
    "If you have a string, bit of tex, or chunk of markdown that isn't coming directly from **pandas**, you can use base Python to write it to a file. Let's say we wanted to take some text,\n",
    "\n",
    "```python\n",
    "text = 'The greatest improvement in the productive powers of labour, and the greater part of the skill, dexterity, and judgment with which it is anywhere directed, or applied, seem to have been the effects of the division of labour.'\n",
    "```\n",
    "\n",
    "and write it to file. The command would be\n",
    "\n",
    "```python\n",
    "open('file.txt', 'w').write(text)\n",
    "```\n",
    "\n",
    "## Review\n",
    "\n",
    "If you know how to read in data and text from file(s), and write out to file too, then you've mastered the content of this chapter!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.8",
    "jupytext_version": "1.5.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit ('codeforecon': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "source_map": [
   14,
   28,
   37,
   102,
   108
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}